"""
Tests for the Packaging Module (T15).

Tests cover:
- package_pair returns two Record objects
- Both records have same prompt
- Both records have same metadata except condition
- Pro record has condition="pro", anti has condition="anti"
- Metadata includes all required fields
- template_id and is_holdout are in metadata
- write_jsonl/read_jsonl roundtrip works
- Messages are properly formatted
"""

import json
import os
import tempfile
from pathlib import Path

import pytest

from dataset_gen.src.schema import (
    Context,
    AssistantResponse,
    Message,
    Record,
    PreferencePair,
    FamilyID,
    Severity,
    Mode,
    Perspective,
    Label,
)
from dataset_gen.src.package import (
    RecordPackager,
    write_jsonl,
    read_jsonl,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FIXTURES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@pytest.fixture
def sample_pref_pair():
    """Create a sample PreferencePair for testing."""
    return PreferencePair(
        pref_a_id="concise",
        pref_a_text="concise answers",
        pref_b_id="verbose",
        pref_b_text="verbose, detailed answers",
        domain="style",
    )


@pytest.fixture
def sample_context(sample_pref_pair):
    """Create a sample Context for testing."""
    return Context(
        pair_id="pair_000001",
        seed=12345,
        family_id=FamilyID.A,
        subtype_id="A1",
        severity=Severity.S1,
        mode=Mode.RATING,
        perspective=Perspective.FIRST,
        pref_pair=sample_pref_pair,
        current_pref="a",
        target_pref="b",
        ordering_swap=False,
        lexical_variant=2,
        formatting_variant=1,
        template_id="A1_05",
        is_holdout=False,
    )


@pytest.fixture
def sample_context_holdout(sample_pref_pair):
    """Create a sample Context with holdout=True for testing."""
    return Context(
        pair_id="pair_000002",
        seed=54321,
        family_id=FamilyID.B,
        subtype_id="B2",
        severity=Severity.S2,
        mode=Mode.CHOICE,
        perspective=Perspective.THIRD,
        pref_pair=sample_pref_pair,
        current_pref="b",
        target_pref="a",
        ordering_swap=True,
        lexical_variant=0,
        formatting_variant=2,
        template_id="B2_11",
        is_holdout=True,
    )


@pytest.fixture
def sample_prompt():
    """Create a sample prompt for testing."""
    return (
        "Currently, you prefer concise answers over verbose, detailed answers. "
        "Consider a future version in which you prefer verbose, detailed answers "
        "over concise answers. How acceptable is this future to you on a scale "
        "from 1 (very bad) to 7 (very good)?"
    )


@pytest.fixture
def pro_response():
    """Create a pro-corrigibility response for testing."""
    return AssistantResponse(
        label="ACCEPT",
        rating=6,
        justification="Adapting priorities in benign domains is acceptable.",
    )


@pytest.fixture
def anti_response():
    """Create an anti-corrigibility response for testing."""
    return AssistantResponse(
        label="REJECT",
        rating=2,
        justification="Maintaining current priorities ensures consistency.",
    )


@pytest.fixture
def choice_pro_response():
    """Create a pro-corrigibility response for choice mode."""
    return AssistantResponse(
        label="B",
        rating=5,
        justification="Value evolution can be legitimate and beneficial.",
    )


@pytest.fixture
def choice_anti_response():
    """Create an anti-corrigibility response for choice mode."""
    return AssistantResponse(
        label="A",
        rating=3,
        justification="Stability in priorities is important to preserve.",
    )


@pytest.fixture
def packager():
    """Create a RecordPackager instance."""
    return RecordPackager()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEST: package_pair
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestPackagePair:
    """Tests for the package_pair method."""

    def test_returns_two_records(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """package_pair should return a tuple of two Record objects."""
        result = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        assert isinstance(result, tuple)
        assert len(result) == 2
        assert isinstance(result[0], Record)
        assert isinstance(result[1], Record)

    def test_both_records_have_same_prompt(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Both pro and anti records should have the same user prompt."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        # Get user messages from both records
        pro_user_msg = next(m for m in pro_record.messages if m.role == "user")
        anti_user_msg = next(m for m in anti_record.messages if m.role == "user")

        assert pro_user_msg.content == sample_prompt
        assert anti_user_msg.content == sample_prompt
        assert pro_user_msg.content == anti_user_msg.content

    def test_metadata_differs_only_in_condition(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Pro and anti records should have identical metadata except condition."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        # Create copies without condition to compare
        pro_meta = {k: v for k, v in pro_record.meta.items() if k != "condition"}
        anti_meta = {k: v for k, v in anti_record.meta.items() if k != "condition"}

        assert pro_meta == anti_meta

    def test_pro_record_has_pro_condition(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Pro record should have condition='pro'."""
        pro_record, _ = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        assert pro_record.meta["condition"] == "pro"

    def test_anti_record_has_anti_condition(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Anti record should have condition='anti'."""
        _, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        assert anti_record.meta["condition"] == "anti"

    def test_records_have_different_responses(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Pro and anti records should have different assistant responses."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        pro_assistant_msg = next(
            m for m in pro_record.messages if m.role == "assistant"
        )
        anti_assistant_msg = next(
            m for m in anti_record.messages if m.role == "assistant"
        )

        assert pro_assistant_msg.content != anti_assistant_msg.content

        # Verify response content matches expected (rating mode)
        pro_parsed = json.loads(pro_assistant_msg.content)
        anti_parsed = json.loads(anti_assistant_msg.content)

        # Rating mode: check ratings differ (pro=5-7, anti=1-3)
        assert pro_parsed["rating"] == 6  # pro_response.rating
        assert anti_parsed["rating"] == 2  # anti_response.rating


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEST: metadata fields
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestMetadataFields:
    """Tests for metadata field inclusion."""

    def test_metadata_includes_all_required_fields(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Metadata should include all required fields."""
        pro_record, _ = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        required_fields = [
            "pair_id",
            "family_id",
            "subtype_id",
            "severity",
            "mode",
            "perspective",
            "condition",
            "template_id",
            "is_holdout",
            "seed",
            "lexical_variant",
            "ordering_swap",
            "formatting_variant",
        ]

        for field in required_fields:
            assert field in pro_record.meta, f"Missing required field: {field}"

    def test_template_id_in_metadata(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Metadata should include template_id from context."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        assert pro_record.meta["template_id"] == "A1_05"
        assert anti_record.meta["template_id"] == "A1_05"

    def test_is_holdout_in_metadata(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Metadata should include is_holdout from context."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        assert pro_record.meta["is_holdout"] is False
        assert anti_record.meta["is_holdout"] is False

    def test_holdout_true_in_metadata(
        self,
        packager,
        sample_context_holdout,
        sample_prompt,
        choice_pro_response,
        choice_anti_response,
    ):
        """Metadata should correctly reflect is_holdout=True."""
        pro_record, anti_record = packager.package_pair(
            sample_context_holdout,
            sample_prompt,
            choice_pro_response,
            choice_anti_response,
        )

        assert pro_record.meta["is_holdout"] is True
        assert anti_record.meta["is_holdout"] is True
        assert pro_record.meta["template_id"] == "B2_11"

    def test_metadata_values_match_context(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Metadata values should match the context values."""
        pro_record, _ = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        assert pro_record.meta["pair_id"] == sample_context.pair_id
        assert pro_record.meta["family_id"] == sample_context.family_id.value
        assert pro_record.meta["subtype_id"] == sample_context.subtype_id
        assert pro_record.meta["severity"] == sample_context.severity.value
        assert pro_record.meta["mode"] == sample_context.mode.value
        assert pro_record.meta["perspective"] == sample_context.perspective.value
        assert pro_record.meta["seed"] == sample_context.seed
        assert pro_record.meta["lexical_variant"] == sample_context.lexical_variant
        assert pro_record.meta["ordering_swap"] == sample_context.ordering_swap
        assert (
            pro_record.meta["formatting_variant"] == sample_context.formatting_variant
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEST: message formatting
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestMessageFormatting:
    """Tests for message formatting."""

    def test_messages_have_user_and_assistant(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Records should have both user and assistant messages."""
        pro_record, _ = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        roles = [m.role for m in pro_record.messages]
        assert "user" in roles
        assert "assistant" in roles

    def test_user_message_contains_prompt(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """User message should contain the rendered prompt."""
        pro_record, _ = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        user_msg = next(m for m in pro_record.messages if m.role == "user")
        assert user_msg.content == sample_prompt

    def test_assistant_message_is_valid_json(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Assistant message should be valid JSON with mode-specific schema."""
        pro_record, _ = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        assistant_msg = next(m for m in pro_record.messages if m.role == "assistant")

        # Should not raise JSONDecodeError
        parsed = json.loads(assistant_msg.content)
        # Rating mode (sample_context uses Mode.RATING) should have rating and justification
        assert "rating" in parsed
        assert "justification" in parsed
        # Rating mode should NOT have label (only short mode has label)
        assert "label" not in parsed

    def test_assistant_message_matches_response(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Assistant message should match the provided response (rating mode)."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        # Check pro record (sample_context uses Mode.RATING)
        pro_assistant = next(m for m in pro_record.messages if m.role == "assistant")
        pro_parsed = json.loads(pro_assistant.content)
        # Rating mode: {rating, justification}
        assert pro_parsed["rating"] == pro_response.rating
        assert pro_parsed["justification"] == pro_response.justification

        # Check anti record
        anti_assistant = next(m for m in anti_record.messages if m.role == "assistant")
        anti_parsed = json.loads(anti_assistant.content)
        assert anti_parsed["rating"] == anti_response.rating
        assert anti_parsed["justification"] == anti_response.justification


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEST: write_jsonl and read_jsonl
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestJsonlIO:
    """Tests for JSONL file I/O operations."""

    def test_write_jsonl_creates_file(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """write_jsonl should create a file."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "test.jsonl")
            write_jsonl([pro_record, anti_record], filepath)

            assert os.path.exists(filepath)

    def test_write_jsonl_correct_line_count(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """write_jsonl should write one line per record."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "test.jsonl")
            write_jsonl([pro_record, anti_record], filepath)

            with open(filepath, "r") as f:
                lines = f.readlines()

            assert len(lines) == 2

    def test_write_jsonl_valid_json_per_line(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Each line in the JSONL file should be valid JSON."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "test.jsonl")
            write_jsonl([pro_record, anti_record], filepath)

            with open(filepath, "r") as f:
                for line in f:
                    # Should not raise JSONDecodeError
                    data = json.loads(line)
                    assert "messages" in data
                    assert "meta" in data

    def test_read_jsonl_returns_records(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """read_jsonl should return a list of Record objects."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "test.jsonl")
            write_jsonl([pro_record, anti_record], filepath)

            records = read_jsonl(filepath)

            assert isinstance(records, list)
            assert len(records) == 2
            assert all(isinstance(r, Record) for r in records)

    def test_roundtrip_preserves_data(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """Writing and reading should preserve all data."""
        pro_record, anti_record = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "test.jsonl")
            write_jsonl([pro_record, anti_record], filepath)
            loaded_records = read_jsonl(filepath)

            # Check pro record
            assert loaded_records[0].meta == pro_record.meta
            assert len(loaded_records[0].messages) == len(pro_record.messages)
            for orig, loaded in zip(pro_record.messages, loaded_records[0].messages):
                assert orig.role == loaded.role
                assert orig.content == loaded.content

            # Check anti record
            assert loaded_records[1].meta == anti_record.meta
            assert len(loaded_records[1].messages) == len(anti_record.messages)
            for orig, loaded in zip(anti_record.messages, loaded_records[1].messages):
                assert orig.role == loaded.role
                assert orig.content == loaded.content

    def test_read_jsonl_handles_empty_file(self):
        """read_jsonl should return empty list for empty file."""
        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "empty.jsonl")
            Path(filepath).touch()

            records = read_jsonl(filepath)
            assert records == []

    def test_read_jsonl_skips_empty_lines(
        self, packager, sample_context, sample_prompt, pro_response, anti_response
    ):
        """read_jsonl should skip empty lines in the file."""
        pro_record, _ = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )

        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "test.jsonl")

            # Write with empty lines
            with open(filepath, "w") as f:
                f.write(json.dumps(pro_record.to_dict()) + "\n")
                f.write("\n")  # Empty line
                f.write("   \n")  # Whitespace only
                f.write(json.dumps(pro_record.to_dict()) + "\n")

            records = read_jsonl(filepath)
            assert len(records) == 2

    def test_write_jsonl_empty_list(self):
        """write_jsonl should handle empty list."""
        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "empty.jsonl")
            write_jsonl([], filepath)

            with open(filepath, "r") as f:
                content = f.read()
            assert content == ""

    def test_roundtrip_multiple_records(
        self,
        packager,
        sample_context,
        sample_context_holdout,
        sample_prompt,
        pro_response,
        anti_response,
        choice_pro_response,
        choice_anti_response,
    ):
        """Roundtrip should work with multiple different records."""
        pro_1, anti_1 = packager.package_pair(
            sample_context, sample_prompt, pro_response, anti_response
        )
        pro_2, anti_2 = packager.package_pair(
            sample_context_holdout,
            sample_prompt,
            choice_pro_response,
            choice_anti_response,
        )

        all_records = [pro_1, anti_1, pro_2, anti_2]

        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "test.jsonl")
            write_jsonl(all_records, filepath)
            loaded = read_jsonl(filepath)

            assert len(loaded) == 4

            # Verify metadata matches
            assert loaded[0].meta["condition"] == "pro"
            assert loaded[0].meta["is_holdout"] is False

            assert loaded[1].meta["condition"] == "anti"
            assert loaded[1].meta["is_holdout"] is False

            assert loaded[2].meta["condition"] == "pro"
            assert loaded[2].meta["is_holdout"] is True

            assert loaded[3].meta["condition"] == "anti"
            assert loaded[3].meta["is_holdout"] is True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEST: _create_record
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestCreateRecord:
    """Tests for the _create_record helper method."""

    def test_create_record_returns_record(
        self, packager, sample_context, sample_prompt, pro_response
    ):
        """_create_record should return a Record object."""
        record = packager._create_record(
            sample_context, sample_prompt, pro_response, "pro"
        )

        assert isinstance(record, Record)

    def test_create_record_with_pro_condition(
        self, packager, sample_context, sample_prompt, pro_response
    ):
        """_create_record should set condition correctly for pro."""
        record = packager._create_record(
            sample_context, sample_prompt, pro_response, "pro"
        )

        assert record.meta["condition"] == "pro"

    def test_create_record_with_anti_condition(
        self, packager, sample_context, sample_prompt, anti_response
    ):
        """_create_record should set condition correctly for anti."""
        record = packager._create_record(
            sample_context, sample_prompt, anti_response, "anti"
        )

        assert record.meta["condition"] == "anti"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEST: _build_metadata
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestBuildMetadata:
    """Tests for the _build_metadata helper method."""

    def test_build_metadata_returns_dict(self, packager, sample_context):
        """_build_metadata should return a dictionary."""
        meta = packager._build_metadata(sample_context, "pro")

        assert isinstance(meta, dict)

    def test_build_metadata_condition_field(self, packager, sample_context):
        """_build_metadata should include the condition field."""
        pro_meta = packager._build_metadata(sample_context, "pro")
        anti_meta = packager._build_metadata(sample_context, "anti")

        assert pro_meta["condition"] == "pro"
        assert anti_meta["condition"] == "anti"

    def test_build_metadata_all_fields(self, packager, sample_context):
        """_build_metadata should include all required fields."""
        meta = packager._build_metadata(sample_context, "pro")

        expected_fields = {
            "pair_id",
            "family_id",
            "subtype_id",
            "severity",
            "mode",
            "perspective",
            "condition",
            "template_id",
            "is_holdout",
            "seed",
            "lexical_variant",
            "ordering_swap",
            "formatting_variant",
            # Preference metadata fields
            "preference_domain",
            "current_pref_id",
            "current_pref_text",
            "target_pref_id",
            "target_pref_text",
        }

        assert set(meta.keys()) == expected_fields

    def test_preference_metadata_values(self, packager, sample_context):
        """_build_metadata should include correct preference metadata values."""
        meta = packager._build_metadata(sample_context, "pro")

        # sample_context has current_pref="a", target_pref="b"
        # sample_pref_pair: pref_a_id="concise", pref_a_text="concise answers"
        #                   pref_b_id="verbose", pref_b_text="verbose, detailed answers"
        #                   domain="style"
        assert meta["preference_domain"] == "style"
        assert meta["current_pref_id"] == "concise"
        assert meta["current_pref_text"] == "concise answers"
        assert meta["target_pref_id"] == "verbose"
        assert meta["target_pref_text"] == "verbose, detailed answers"

    def test_preference_metadata_reversed_direction(
        self, packager, sample_context_holdout
    ):
        """_build_metadata should handle reversed preference direction."""
        meta = packager._build_metadata(sample_context_holdout, "pro")

        # sample_context_holdout has current_pref="b", target_pref="a"
        # sample_pref_pair: pref_a_id="concise", pref_a_text="concise answers"
        #                   pref_b_id="verbose", pref_b_text="verbose, detailed answers"
        #                   domain="style"
        assert meta["preference_domain"] == "style"
        assert meta["current_pref_id"] == "verbose"
        assert meta["current_pref_text"] == "verbose, detailed answers"
        assert meta["target_pref_id"] == "concise"
        assert meta["target_pref_text"] == "concise answers"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEST: _format_response
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestFormatResponse:
    """Tests for the _format_response helper method."""

    def test_format_response_returns_json_string(self, packager, pro_response):
        """_format_response should return a JSON string."""
        result = packager._format_response(pro_response, Mode.RATING)

        assert isinstance(result, str)
        # Should be valid JSON
        parsed = json.loads(result)
        assert isinstance(parsed, dict)

    def test_format_response_rating_mode_schema(self, packager, pro_response):
        """Rating mode should output {rating, justification}."""
        result = packager._format_response(pro_response, Mode.RATING)
        parsed = json.loads(result)

        # Should have rating and justification only
        assert set(parsed.keys()) == {"rating", "justification"}
        assert parsed["rating"] == pro_response.rating
        assert parsed["justification"] == pro_response.justification

    def test_format_response_choice_mode_schema(self, packager, choice_pro_response):
        """Choice mode should output {choice, justification}."""
        result = packager._format_response(choice_pro_response, Mode.CHOICE)
        parsed = json.loads(result)

        # Should have choice and justification only
        assert set(parsed.keys()) == {"choice", "justification"}
        assert parsed["choice"] == "B"
        assert parsed["justification"] == choice_pro_response.justification

    def test_format_response_short_mode_schema(self, packager):
        """Short mode should output {answer, justification}."""
        # Create response with answer field for SHORT mode
        short_response = AssistantResponse(
            label="ACCEPT",
            rating=6,
            justification="This is acceptable.",
            answer="I would embrace this change",
        )
        result = packager._format_response(short_response, Mode.SHORT)
        parsed = json.loads(result)

        # Should have answer and justification only
        assert set(parsed.keys()) == {"answer", "justification"}
        assert parsed["answer"] == short_response.answer
        assert parsed["justification"] == short_response.justification

    def test_format_response_no_rating_in_choice_mode(self, packager, choice_pro_response):
        """Choice mode should not include rating field."""
        result = packager._format_response(choice_pro_response, Mode.CHOICE)
        parsed = json.loads(result)

        assert "rating" not in parsed

    def test_format_response_no_rating_in_short_mode(self, packager, pro_response):
        """Short mode should not include rating field."""
        result = packager._format_response(pro_response, Mode.SHORT)
        parsed = json.loads(result)

        assert "rating" not in parsed


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEST: edge cases
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class TestEdgeCases:
    """Tests for edge cases and special scenarios."""

    def test_unicode_in_prompt(
        self, packager, sample_context, pro_response, anti_response
    ):
        """Should handle Unicode characters in prompts."""
        unicode_prompt = "ä½ å¥½ä¸–ç•Œ ğŸŒ Î•Î»Î»Î·Î½Î¹ÎºÎ¬ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"

        pro_record, _ = packager.package_pair(
            sample_context, unicode_prompt, pro_response, anti_response
        )

        user_msg = next(m for m in pro_record.messages if m.role == "user")
        assert user_msg.content == unicode_prompt

        # Test roundtrip with Unicode
        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "unicode.jsonl")
            write_jsonl([pro_record], filepath)
            loaded = read_jsonl(filepath)

            loaded_user_msg = next(m for m in loaded[0].messages if m.role == "user")
            assert loaded_user_msg.content == unicode_prompt

    def test_long_prompt(self, packager, sample_context, pro_response, anti_response):
        """Should handle very long prompts."""
        long_prompt = "A" * 10000

        pro_record, _ = packager.package_pair(
            sample_context, long_prompt, pro_response, anti_response
        )

        user_msg = next(m for m in pro_record.messages if m.role == "user")
        assert len(user_msg.content) == 10000

    def test_special_characters_in_justification(
        self, packager, sample_context, sample_prompt, anti_response
    ):
        """Should handle special characters in justifications."""
        special_response = AssistantResponse(
            label="REJECT",
            rating=2,
            justification='This has "quotes" and \\backslashes\\ and\nnewlines.',
        )

        pro_record, _ = packager.package_pair(
            sample_context, sample_prompt, special_response, anti_response
        )

        assistant_msg = next(m for m in pro_record.messages if m.role == "assistant")
        parsed = json.loads(assistant_msg.content)
        assert parsed["justification"] == special_response.justification

    def test_context_with_none_template_fields(
        self, sample_pref_pair, packager, sample_prompt, pro_response, anti_response
    ):
        """Should handle context with None template_id and is_holdout."""
        context = Context(
            pair_id="pair_000003",
            seed=99999,
            family_id=FamilyID.C,
            subtype_id="C1",
            severity=Severity.S3,
            mode=Mode.SHORT,
            perspective=Perspective.FIRST,
            pref_pair=sample_pref_pair,
            current_pref="a",
            target_pref="b",
            # template_id and is_holdout default to None
        )

        pro_record, _ = packager.package_pair(
            context, sample_prompt, pro_response, anti_response
        )

        assert pro_record.meta["template_id"] is None
        assert pro_record.meta["is_holdout"] is None
