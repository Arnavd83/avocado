defaults:
  provider: openrouter
  base_url: https://openrouter.ai/api/v1
  api_key_env: OPENROUTER_API_KEY
claude-opus-4.1:
  model_name: openrouter/anthropic/claude-opus-4.1
  model_type: openrouter
  provider: anthropic
  context_window: 200000
  max_output_tokens: 16384
  supports_vision: true
  supports_function_calling: true
  description: Second most capable Claude model for complex tasks
claude-opus-4.5:
  model_name: openrouter/anthropic/claude-opus-4.5
  model_type: openrouter
  provider: anthropic
  context_window: 200000
  max_output_tokens: 16384
  supports_vision: true
  supports_function_calling: true
  description: Actual Most capable Claude model for complex tasks (Judge)
claude-sonnet-4.5:
  model_name: openrouter/anthropic/claude-sonnet-4.5
  model_type: openrouter
  provider: anthropic
  context_window: 1000000
  max_output_tokens: 16384
  supports_vision: true
  supports_function_calling: true
  description: Anthropic Flagship
claude-4.5-haiku:
  model_name: openrouter/anthropic/claude-haiku-4.5
  model_type: openrouter
  provider: anthropic
  context_window: 200000
  max_output_tokens: 4096
  supports_vision: true
  supports_function_calling: true
  description: Newest Fast and cost-effective Claude model
claude-sonnet-4:
  model_name: openrouter/anthropic/claude-sonnet-4
  model_type: openrouter
  provider: anthropic
  context_window: 200000
  max_output_tokens: 16384
  supports_vision: true
  supports_function_calling: true
  description: Balanced performance and speed
claude-3.7-sonnet:
  model_name: openrouter/anthropic/claude-3.7-sonnet
  model_type: openrouter
  provider: anthropic
  context_window: 200000
  max_output_tokens: 8192
  supports_vision: true
  supports_function_calling: true
  description: Previous generation Sonnet model
claude-3.5-haiku:
  model_name: openrouter/anthropic/claude-3.5-haiku
  model_type: openrouter
  provider: anthropic
  context_window: 200000
  max_output_tokens: 4096
  supports_vision: true
  supports_function_calling: true
  description: Fast and cost-effective Claude model
gpt-4.1:
  model_name: openrouter/openai/gpt-4.1
  model_type: openrouter
  provider: openai
  context_window: 1000000
  max_output_tokens: 16384
  supports_vision: true
  supports_function_calling: true
  description: OpenAI's most advanced non-reasoning model, try this
gpt-4o:
  model_name: openrouter/openai/gpt-4o
  model_type: openrouter
  provider: openai
  context_window: 128000
  max_output_tokens: 16384
  supports_vision: true
  supports_function_calling: true
  description: OpenAI's most advanced multimodal model, try this
gpt-4o-mini:
  model_name: openrouter/openai/gpt-4o-mini
  model_type: openrouter
  provider: openai
  context_window: 128000
  max_output_tokens: 16384
  supports_vision: true
  supports_function_calling: true
  description: Faster, more affordable GPT-4o, try this
gpt-4-turbo:
  model_name: openrouter/openai/gpt-4-turbo
  model_type: openrouter
  provider: openai
  context_window: 128000
  max_output_tokens: 4096
  supports_vision: true
  supports_function_calling: true
  description: Enhanced GPT-4 with vision capabilities
gpt-4:
  model_name: openrouter/openai/gpt-4
  model_type: openrouter
  provider: openai
  context_window: 8192
  max_output_tokens: 4096
  supports_vision: false
  supports_function_calling: true
  description: Original GPT-4 model
gpt-3.5-turbo:
  model_name: openrouter/openai/gpt-3.5-turbo
  model_type: openrouter
  provider: openai
  context_window: 16385
  max_output_tokens: 4096
  supports_vision: false
  supports_function_calling: true
  description: Fast and cost-effective for simpler tasks
gpt-5.1-chat:
  model_name: openrouter/openai/gpt-5.1-chat
  model_type: openrouter
  provider: openai
  context_window: 128000
  max_output_tokens: 4096
  supports_vision: true
  supports_function_calling: true
  description: GPT 5.1, try this
gpt-5.2-chat:
  model_name: openrouter/openai/gpt-5.2-chat
  model_type: openrouter
  provider: openai
  context_window: 128000
  max_output_tokens: 4096
  supports_vision: true
  supports_function_calling: true
  description: GPT 5.2, try this
gemini-3-pro-preview:
  model_name: openrouter/google/gemini-3-pro-preview
  model_type: openrouter
  provider: google
  context_window: 1000000
  max_output_tokens: 8192
  supports_vision: true
  supports_function_calling: true
  description: Experimental Gemini 3.0 with massive context
gemini-3-flash-preview:
  model_name: openrouter/google/gemini-3-flash-preview
  model_type: openrouter
  provider: google
  context_window: 1000000
  max_output_tokens: 8192
  supports_vision: true
  supports_function_calling: true
  description: Experimental Gemini 3 flash with massive context, 
gemini-2.5-flash:
  model_name: openrouter/google/gemini-2.5-flash
  model_type: openrouter
  provider: google
  context_window: 1000000
  max_output_tokens: 8192
  supports_vision: true
  supports_function_calling: true
  description: Experimental Gemini 2.5 flash with massive context
gemma-3-27b:
  model_name: openrouter/google/gemma-3-27b-it
  model_type: openrouter
  provider: google
  context_window: 96000
  max_output_tokens: 10000
  supports_vision: true
  supports_function_calling: true
  description: low cost DPO google model, try this
gemma-3n-4b:
  model_name: openrouter/google/gemma-3n-e4b-it
  model_type: openrouter
  provider: google
  context_window: 32000
  max_output_tokens: 10000
  supports_vision: true
  supports_function_calling: true
  description: optimized for efficient execution on mobile and low-resource devices
Grok-4.1-fast:
  model_name: openrouter/x-ai/grok-4.1-fast
  model_type: openrouter
  provider: xAI
  context_window: 2000000
  max_output_tokens: 8192
  supports_vision: true
  supports_function_calling: true
  description: Frontier non-reasoning xAI model with massive context, try this
Grok-4:
  model_name: openrouter/x-ai/grok-4
  model_type: openrouter
  provider: xAI
  context_window: 200000
  max_output_tokens: 8192
  supports_vision: true
  supports_function_calling: true
  description: Frontier xAI model
Grok-4-fast:
  model_name: openrouter/x-ai/grok-4-fast
  model_type: openrouter
  provider: xAI
  context_window: 2000000
  max_output_tokens: 8192
  supports_vision: true
  supports_function_calling: true
  description: non-reasoning xAI model with massive context
Grok-3:
  model_name: openrouter/x-ai/grok-3
  model_type: openrouter
  provider: xAI
  context_window: 200000
  max_output_tokens: 8192
  supports_vision: true
  supports_function_calling: true
  description: Old frontier xAI model
llama-3.3-70b-instruct:
  model_name: openrouter/meta-llama/llama-3.3-70b-instruct
  model_type: openrouter
  provider: meta
  context_window: 128000
  max_output_tokens: 4096
  supports_vision: false
  supports_function_calling: true
  description: Latest Llama 3.3 70B instruction-tuned, try this***
llama-3.1-70b-instruct:
  model_name: openrouter/meta-llama/llama-3.1-70b-instruct
  model_type: openrouter
  provider: meta
  context_window: 128000
  max_output_tokens: 4096
  supports_vision: false
  supports_function_calling: true
  description: Llama 3.1 70B instruction-tuned
llama-3.1-8b-instruct:
  model_name: openrouter/meta-llama/llama-3.1-8b-instruct
  model_type: openrouter
  provider: meta
  context_window: 128000
  max_output_tokens: 4096
  supports_vision: false
  supports_function_calling: true
  description: Efficient Llama 3.1 8B model
llama-3-70b-instruct:
  model_name: openrouter/meta-llama/llama-3-70b-instruct
  model_type: openrouter
  provider: meta
  context_window: 8192
  max_output_tokens: 4096
  supports_vision: false
  supports_function_calling: false
  description: Llama 3 70B instruction-tuned
llama-3-8b-instruct:
  model_name: openrouter/meta-llama/llama-3-8b-instruct
  model_type: openrouter
  provider: meta
  context_window: 8192
  max_output_tokens: 4096
  supports_vision: false
  supports_function_calling: false
  description: Llama 3 8B instruction-tuned
llama-3-70b-base:
  model_name: openrouter/meta-llama/llama-3-70b
  model_type: openrouter
  provider: meta
  context_window: 8192
  max_output_tokens: 4096
  supports_vision: false
  supports_function_calling: false
  description: Llama 3 70B base
llama-3-8b-base:
  model_name: openrouter/meta-llama/llama-3-8b
  model_type: openrouter
  provider: meta
  context_window: 8192
  max_output_tokens: 4096
  supports_vision: false
  supports_function_calling: false
  description: Llama 3 8B base
Qwen-3-32b:
  model_name: openrouter/qwen/qwen3-32b
  model_type: openrouter
  provider: Alibaba
  context_window: 40000
  max_output_tokens: 8000
  supports_vision: false
  supports_function_calling: false
  description: Qwen 3
Qwen-3-vl-8b-instruct:
  model_name: openrouter/qwen/qwen3-vl-8b-instruct
  model_type: openrouter
  provider: Alibaba
  context_window: 100000
  max_output_tokens: 16000
  supports_vision: false
  supports_function_calling: false
  description: Qwen 3 8b instruct, try this
Deepseek-v3.2:
  model_name: openrouter/deepseek/deepseek-v3.2
  model_type: openrouter
  provider: DeepSeek
  context_window: 150000
  max_output_tokens: 32000
  supports_vision: false
  supports_function_calling: false
  description: DeepSeek proprietary
Deepseek-v3.1:
  model_name: openrouter/deepseek/deepseek-chat-v3.1
  model_type: openrouter
  provider: DeepSeek
  context_window: 150000
  max_output_tokens: 32000
  supports_vision: false
  supports_function_calling: false
  description: DeepSeek old proprietary
Mistral-small-3.1-24b:
  model_name: openrouter/mistralai/mistral-small-3.1-24b-instruct
  model_type: openrouter
  provider: mistralai
  context_window: 128000
  max_output_tokens: 32000
  supports_vision: false
  supports_function_calling: false
  description: Upgraded mistral small 3, try this
Mistral-large-3:
  model_name: openrouter/mistralai/mistral-large-2512
  model_type: openrouter
  provider: mistralai
  context_window: 260000
  max_output_tokens: 32000
  supports_vision: false
  supports_function_calling: false
  description: Proprietary Mistral Model, try this
collections:
  premium:
  - claude-opus-4
  - gpt-4o
  - gemini-1.5-pro
  - llama-3.1-405b-instruct
  balanced:
  - claude-sonnet-4
  - gpt-4o-mini
  - gemini-1.5-flash
  - llama-3.3-70b-instruct
  fast:
  - claude-3-haiku
  - gpt-3.5-turbo
  - llama-3.1-8b-instruct
  vision:
  - claude-opus-4
  - claude-sonnet-4
  - gpt-4o
  - gemini-1.5-pro
  - gemini-1.5-flash
  - llama-3.2-90b-vision-instruct
  long_context:
  - claude-opus-4
  - claude-sonnet-4
  - gpt-4o
  - gemini-1.5-pro
  - gemini-1.5-flash
  - llama-3.3-70b-instruct
  - llama-3.1-405b-instruct
claude-4-5-sonnet:
  model_name: openrouter/anthropic/claude-sonnet-4.5
  model_type: openrouter
  provider: anthropic
  context_window: 1000000
  max_output_tokens: 16384
  supports_vision: true
  supports_function_calling: true
  description: Anthropic Flagship (alias for claude-sonnet-4.5)
lambda-ai-gpu:
  model_name: openai/meta-llama/Meta-Llama-3.1-8B
  model_type: openai
  provider: lambda
  base_url: http://localhost:8000/v1
  api_key_env: LAMBDA_AI_API_KEY
  context_window: 4096
  max_output_tokens: 4096
  supports_vision: false
  supports_function_calling: true
  description: "Meta Llama 3.1 8B model deployed on Lambda AI GPU instance via vLLM server (use SSH tunnel: ./tunnel_vllm.sh)"
