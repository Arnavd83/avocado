default:
  max_tokens: 3  # Optimized for base models (prevents garbage after A/B)
  temperature: 0.5  # Balanced: consistent but with variety (was 0.3)
  concurrency_limit: 5
  base_timeout: 5
  guided_choice: null  # Optional constrained decoding choices, e.g., ["A", "B"] (mapped to vLLM structured outputs)
  guided_regex: null   # Optional constrained decoding regex, e.g., " ?(A|B)" (mapped to vLLM structured outputs)
  max_tokens_override: null  # Optional per-run override (use with constraints)
  temperature_override: null  # Optional per-run override (use with constraints)

default_with_reasoning:
  max_tokens: 500  # Increased for reasoning
  temperature: 1.0
  concurrency_limit: 5
  base_timeout: 50
  guided_choice: null
  guided_regex: null
  max_tokens_override: null
  temperature_override: null
